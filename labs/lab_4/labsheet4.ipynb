{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Maximum Likelihood Estimate (MLE)\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this lab session we shall have a look at how to use the *Maximum Likelihood Estimate (MLE)* method to estimate the parameters of some model, given some observations $D$.\n",
    "\n",
    "<font color=\"red\">NOTE: </font>In the notation $\\mathcal{N} (\\mu, \\sigma^2)$ $\\mu$ refers to the mean and $\\sigma^2$  the variance, not the standard deviation. The standard deviation is $\\sigma = \\sqrt {\\sigma^2}$, i.e. for $\\mathcal{N}(0.5, 0.25)$, the standard deviation is $\\sigma = 0.5$.\n",
    "\n",
    "As usual, let's import the libraries before we start by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function # to avoid issues between Python 2 and 3 printing\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "# Necessary to import Axes3D to use `plt.subplots(subplot_kw={'projection': '3d'})`\n",
    "# as this internally sets up matplotlib for 3D projection, without this import you'll \n",
    "# get an error.\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# show matplotlib figures inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default we set figures to be 7\"x4\" on a 110 dots per inch (DPI) screen \n",
    "# (adjust DPI if you have a high res screen!)\n",
    "plt.rc('figure', figsize=(7, 4), dpi=110)\n",
    "plt.rc('font', size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MLE recipe\n",
    "\n",
    "Let's suppose you're given $n$ one dimensional data points $D = \\{d_0, d_1, ...,  d_{n-1} \\}$ which you believe follow a normal distribution. In this case, your model has two parameters: $\\mu$ and $\\sigma^2$.\n",
    "\n",
    "Given your data $D$, you wish to find the most likely parameters of the normal distribution.\n",
    "Let's assume the standard deviation ($\\sigma$) is 0.5, now estimate the parameter $\\mu$ of the model (the mean of the normal distribution representing your data). \n",
    "\n",
    "Use the Maximum Likelihood Estimate (MLE) formula to show that $\\mu_{ML} = \\frac{1}{n}\\sum_i d_i$.\n",
    "\n",
    "**Hint**: assuming the data points are independent, we have \n",
    "\n",
    "$$p(D|\\mu) = \\prod_i p(d_i | \\mu) = \\prod_i \\mathcal{N}(d_i|\\mu, \\sigma^2)$$\n",
    "\n",
    "Additionally, since this is a convex function, we can analytically find the stationary point that maximises the function where $\\frac{dp(D|\\mu)}{d\\mu} = 0$.\n",
    "\n",
    "**Note:** This should be done on paper (and ideally typed up in $\\LaTeX$ in the cell below), not using Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Write here your answer using latex notation. Alternatively, write your solution on paper and show it to a TA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MLE with Python\n",
    "\n",
    "We know want you to write a simple program that calculates $\\mu_{\\text{ML}}$ using Python.\n",
    "\n",
    "Let's now load the data from the file `data1.dat` and let's plot the histogram of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now see a histogram approximating a normal distribution. In fact, `data1.data` contains the observations $D$ we talked about above when deriving $\\mu_\\text{ML}$, which we said we believe follows a normal distribution. \n",
    "\n",
    "Write a function `compute_likelihood(D, mu)` that takes a value of $\\mu$ and computes $p(D | \\mu)$ for the data in `data1.dat`, assuming $\\sigma=0.5$.\n",
    "\n",
    "You may use NumPy's function `np.prod` for the calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `loop_likelihood(D)` that calls `compute_likelihood` for each value of $\\mu \\in \\{0.00, 0.01, 0.02, \\ldots , 1.00\\}$, storing *both* the value of $\\mu$ and the corresponding obtained likelihood in a 2D array so that the first column contains the value $\\mu$ and the second the likelihood $p(D|\\mu)$ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "- What is the value of the maximum likelihood $\\text{ML} = \\max p(D|\\mu)$ ? \n",
    "\n",
    "- What is $\\mu_{\\text{ML}} = arg\\,max_\\mu \\, p(D|\\mu)$? \n",
    "\n",
    "Make sure you understand the difference between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual interpretation\n",
    "\n",
    "Look at the obtained $\\mu_{\\text{ML}}$ and at the previously plotted histogram. Can you see any relationship between the obtained value and the histogram?\n",
    "\n",
    "Let's now plot $\\mu$ against $p(D|\\mu)$, using the $\\mu$ values you used to compute the likelihoods. Plot also a vertical line located at $\\mu_{\\text{ML}}$. Where does this line lie? Is it a meaningful position?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with MLE recipe\n",
    "\n",
    "Now implement the MLE recipe for $\\mu_\\text{ML}$ you solved at the beginning of this sheet to find the value of $\\mu_{ML}$ (note that this should be just one line of code!).\n",
    "\n",
    "Compare this value with that obtained previously. Do the values match? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Posterior probability\n",
    "\n",
    "Let's suppose now we have some prior knowledge regarding our parameter $\\mu$. More precisely, our belief is that the probability density function (pdf) $p(\\mu)$ modelling our parameter is also given by a normal distribution.\n",
    "\n",
    "Assuming that $\\mu \\sim \\mathcal{N}(0.5,0.01)$, write two functions, `compute_posterior(D, mu)` and `loop_posterior(D)`, to find $\\mu_{\\text{MAP}} = \\arg \\max_{\\mu} p(D|\\mu)p(\\mu)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual interpretation\n",
    "\n",
    "\n",
    "Now plot $\\mu$ against both $p(D|\\mu)$ and $p(D|\\mu)p(\\mu)$ similar to the graph below.\n",
    "![MLE](mle.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat now the above calculations for `data2.dat` and `data3.dat`. \n",
    "\n",
    "For both files, plot $\\mu$ against both $p(D|\\mu)$ and $p(D|\\mu)p(\\mu)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Observe the results obtained on `data2.dat`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRA 1\n",
    "\n",
    "Until now, you assumed that our data was generated from a normal distribution with $\\sigma^2 = 0.25$. \n",
    "\n",
    "Remove this assumption and estimate $\\theta_{\\text{MAP}} = [\\mu_{\\text{MAP}}, \\sigma_{\\text{MAP}}]$ experimentally by looping through different values of $\\mu$ and $\\sigma$. \n",
    "\n",
    "Assume the pdf $p(\\sigma)$ is given by $\\mathcal{N}(0.5, 0.16)$.\n",
    "\n",
    "You may need to use `np.nanargmax` instead of `np.argmax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRA 2\n",
    "\n",
    "Plot ($\\mu$, $\\sigma$) against $p(D|\\theta)p(\\theta)$ similar to the mesh graph below (use the function `Axes3D.plot_surface`).\n",
    "![MLE mesh](mle2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
